
<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta charset="UTF-8">

    <title>My Tech Odyssey</title>

    <!-- style -->
    <link rel="stylesheet" href="style.css">
    
    <!-- images -->
    <link rel="stylesheet" href="https://unpkg.com/viewerjs/dist/viewer.min.css">
    <script src="https://unpkg.com/viewerjs/dist/viewer.min.js"></script>

    <!-- video -->
    <script src="https://unpkg.com/video.js/dist/video.js"></script>
    <link href="https://unpkg.com/video.js/dist/video-js.min.css" rel="stylesheet">

    <!-- common js functionality -->
    <script defer src="script.js"></script>
</head
>
<body>
    <section id="tech_odyssey" class="section">
        <div id="tech_odyssey_content">

            <div class="project_class toggle" data-target="cv" onclick="toggleContent()">
                <h1 class="class_title">
                    Computer Vision / Deep Learning
                </h1>

                <!-- content 1 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        VizFlyt: Perception-centric Pedagogical Framework For Autonomous Aerial Robots
                        <div class="org_year">
                            <span class="org_name">WPI</span>
                            <span class="year_tag">2024</span>
                        </div>
                    </h2>
                    <p>Autonomous aerial robots are becoming commonplace in our lives. Hands-on aerial robotics courses are pivotal in training the next-generation workforce to meet the growing market demands. Such an efficient and compelling course depends on a reliable testbed. In this paper, we present VizFlyt, an open-source perception-centric Hardware-In-The-Loop (HITL) photorealistic testing framework for aerial robotics courses. We utilize pose from an external localization system to hallucinate real-time and photorealistic visual sensors using 3D Gaussian Splatting. This enables stress-free testing of autonomy algorithms on aerial robots without the risk of crashing into obstacles. We achieve over 100Hz of system update rate. Lastly, we build upon our past experiences of offering hands-on aerial robotics courses and propose a new open-source and open-hardware curriculum based on VizFlyt for the future. We test our framework on various course projects in real-world HITL experiments and present the results showing the efficacy of such a system and its large potential use cases.</p>
                    <p>M. Velmurugan*, K. Srivastava*, R. Kulkarni*, and N. J. Sanket, "VizFlyt: Perception-centric Pedagogical Framework For Autonomous Aerial Robots," submitted to ICRA 2025 (under review, * means equal contribution).</p>

                    <div class="video_placeholder">
                        <video id="my-video" class="video-js" controls preload="auto" width="900" height="auto" data-setup="{}">
                            <source src="https://dl.dropbox.com/scl/fi/z81u4lgbs0cqcs0z4r4qm/viz_flyt_Sequence-01_7.mp4?rlkey=4j08r8fbpa6pytt8pp2dre2e2&st=dhk5z8k6&dl=0" type="video/mp4" />
                        </video>
                    </div>
                        

                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://pear.wpi.edu/research/vizflyt.html" target="_blank">Visit the project page</a>
                    </div>
                </div>

                <!-- content -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        EinsteinVision: A Deep Learning-Powered 3D Visualization Tool for Autonomous Vehicle Dashboard Displays
                        <div class="org_year">
                            <span class="org_name">WPI</span>
                            <span class="year_tag">2024</span>
                        </div>
                    </h2>
                    <p>EinsteinVision is a self-driving car visualization project aimed at providing visually appealing and informative displays for autonomous vehicle systems. The project was developed during a computer vision course at WPI by Manoj Velmurugan and Rishabh Singh. We used deep learning models to detect objects, human poses, lanes, and depth in images. These detections were converted into 3D coordinates and placed in Blender at the reprojected 3D locations, where they were rendered to create a dashboard visualizer for self-driving vehicles. Deep neural network models like Depth Anything, Mask R-CNN, and OpenPifPaf were used for accurate depth estimation, lane detection, and car pose estimation. Traffic lights, tail lights, and speed bumps were also detected for comprehensive scene understanding.
                        </p>

                    <div class="video_placeholder">
                        <video id="my-video" class="video-js" controls preload="auto" width="900" height="auto" data-setup="{}">
                            <source src="https://dl.dropbox.com/scl/fi/bu0e2nqx931r4e5zpgp4a/OutputVisualizationVideoSeq8_v0_with_human_pose.mp4?rlkey=2l5kkrlb21zxodgp51pj7374p&st=j9ht7ipd&dl=0" type="video/mp4" />
                        </video>
                    </div>
                        

                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://dl.dropbox.com/scl/fi/qj2b2v99fss53vapksirf/einsteinVision_manoj_rishabh.pdf?rlkey=7mmof7rk9eii4b6kbqv0fr8hq&st=4p6duxs3&dl=0" target="_blank">Project Report</a>
                    </div>
                </div>
                
            </div>

            <div class="project_class toggle" data-target="uav" onclick="toggleContent()">
                <h1 class="class_title">
                    Unmanned Aerial Vehicles (UAV)
                </h1>

                <!-- content 1 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        PX4 Hardware-in-the-Loop (HITL) Simulation with Fixed-Wing Plant
                        <div class="org_year">
                            <span class="org_name">MathWorks</span>
                            <span class="year_tag">2022</span>
                        </div>
                    </h2>
                    <p>I developed a Simulink and Stateflow model for flight mode management, guidance, and control of a fixed-wing UAV. The custom controller model integrates into the PX4 stack, enabling seamless flight operations. An L1 guidance scheme was used for path tracking, while a cascaded PID controller architecture, inspired by PX4, was employed for control. <br>I formulated a cascaded control structure to control the following states:</p>
                        <ul>
                            <li>Airspeed</li>
                            <li>Altitude & climb rate</li>
                            <li>Course</li>
                            <li>Attitude & angular rate</li>
                        </ul>
                        <p>Using Embedded Coder, the controller is automatically generated and deployed onto a PX4 Autopilot Pixhawk board. The deployed code is rigorously tested in a Hardware-in-the-Loop (HIL) setup, with the Simulink-based plant model running on a PC or a Speedgoat real-time target computer to ensure accurate and reliable performance. <br>Credits: The plant dynamics model mostly was modified/adopted from Mariano Lizarraga's PhD work.</p>

                    <div class="video_placeholder">
                        <img src="https://dl.dropbox.com/scl/fi/kwxxlrre55nha3ic6zlmn/stateflow_fixedWing.png?rlkey=swgqjf3oehdp1zbvqdx517q1t&st=xrh574rt&dl=0" alt="Stateflow Fixed Wing Controller" style="width: 900px;" class="dynamic-image">
                    </div>
                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://www.mathworks.com/help/uav/px4/ug/px4-fixed-wing-architecture.html" target="_blank">Visit the project page</a>
                    </div>
                </div>
                
                <!-- content 2 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        PX4 Hardware-in-the-Loop (HITL) Simulation with Quadrotor Plant
                        <div class="org_year">
                            <span class="org_name">MathWorks</span>
                            <span class="year_tag">2020-2022</span>
                        </div>
                    </h2>
                    <p>Contributed significantly to the development of a key example in the UAV Toolbox support package for PX4 Autopilots. This example showcases the process of designing controllers for PX4-based autopilots for quadrotors and validating them using a Simulink-based plant model. My work focused on:</p>
                        <ul>
                            <li>Developing the plant dynamics model</li>
                            <li>Designing the controller model, position controllers to angular rate controllers</li>
                            <li>Implementing portions of the sensor simulation</li>
                        </ul>
                        <p>The controller was deployed and tested in a Hardware-in-the-Loop (HIL) configuration, with the Simulink plant model executed on a PC or a Speedgoat real-time target computer to ensure robust validation of the UAV's control system.</p>

                    <!-- <div class="video_placeholder">
                        <img src="https://dl.dropbox.com/scl/fi/qdjc1fz8rwh1y0d9m06tv/hitlQuad.png?rlkey=n90e059fgw6anpyre83bkhbk2&st=ka7hw0ut&dl=0" 
                        alt="HITL Quadrotor Simulation" style="width: 100%; max-width: 1100px;">
                    </div> -->
                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://www.mathworks.com/help/uav/px4/ref/hitl-simulink-plant-example.html" target="_blank">Visit the project page</a>
                    </div>
                </div>

                <!-- content 3 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        Controllers and Estimators for Parrot Minidrone
                        <div class="org_year">
                            <span class="org_name">MathWorks</span>
                            <span class="year_tag">2019-2020</span>
                        </div>
                    </h2>
                    <p>Enhanced the Parrot Minidrone example and addressed issues with the IMU temperature-induced bias, which caused significant errors in attitude and position estimates. Key improvements included:</p>
                    <ul>
                        <li>Replacing the complementary filter with a linear Kalman Filter (KF) for roll and pitch estimation, incorporating gyro bias as a state.</li>
                        <li>Adding accelerometer bias as a state in the existing velocity KF for x and y directions.</li>
                        <li>Redesigning the control architecture from a position PID → attitude PID loop to a cascaded structure: position P → velocity PI → attitude P → angular velocity PID control loops, improving stability and performance.</li>
                        <li>Revising the dynamics, control, and estimator model equations to fix errors in the original formulation.</li>
                    </ul>
                    <p>These modifications resulted in a significant reduction in position drift, from 1 meter to less than 20 cm during a 1-minute flight, and enhanced the controller's responsiveness to disturbances.</p>

                    <div class="video_placeholder">
                        <video id="my-video" class="video-js" controls preload="auto" max-width="400" height="auto" data-setup="{}" poster="https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/63318/versions/6/screenshot.png">
                            <source src="https://dl.dropbox.com/scl/fi/u7x4h8rox5n851m95j0ol/parrotMamboTrimmed.mp4?rlkey=7phu4hvjdd5bge95qjr8rxhln&st=3wdlfx0d&dl=0" type="video/mp4" />
                        </video>
                    </div>

                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://www.mathworks.com/help/simulink/supportpkg/parrot_ug/fly-a-parrot-minidrone-using-the-hover-simulink-model.html" target="_blank">Visit the project page</a>
                    </div>
                </div>

                <!-- content4 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        In-House Autopilot for an Indoor Quadcopter
                        <div class="org_year">
                            <span class="org_name">RAFT Lab, IIT Madras</span>
                            <span class="year_tag">2016-2019</span>
                        </div>
                    </h2>
                    <p>Developed a custom Arm Mbed-based autopilot system for controlling an indoor quadrotor autonomously. 
                        Highlights include:</p>
                    <ul>
                        <li>Engineered multi-loop PID controls with derivative filtering and integral anti-windup, optimizing for a critically damped response and a 0.5-0.8 s settling time.</li>
                        <li>Implemented a complementary filter for pitch, roll, and downward velocity, alongside a linear Kalman Filter for lateral velocities, factoring in accelerometer bias and optical flow data.</li>
                        <li>Derived a realistic quadcopter dynamics model through empirical research on inertia, motor, and propeller characteristics.</li>
                        <li>Authored extensive C++ codebase and designed a custom PCB for sensor interfacing on the ST-Nucleo board.</li>
                        <li>Presented findings at the Indian Control Conference 2019, IIT Delhi, fostering academic and practical applications in aerial robotics.</li>
                    </ul>
                    <p>This project led to robust flight performance and practical educational tools for peers, significantly advancing the capabilities of indoor UAVs.</p>
                    <div class="video_placeholder">
                        <img src="https://dl.dropbox.com/scl/fi/jeyuhesmjy2yaknsvq7wh/fcb.jpg?rlkey=u9w6k4h9ec5db4jfpaht3mn2i&st=sf0upwze&dl=0" alt="Flight Control Board" max-width="900px" class="dynamic-image">
                    </div>
                    <div class="video_placeholder">
                        <iframe width="900px" height="506
                        " src="https://www.youtube.com/embed/Bq1ETXIEwg4?si=bCtAYyG3gjrBHwkq?rel=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </div>
                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://raftlab.iitm.ac.in/" target="_blank">Visit the project page</a>
                    </div>
                </div>
                
                <!-- content 5 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        First Solar-Powered Airplane of IIT Madras
                        <div class="org_year">
                            <span class="org_name">RAFT Lab, IIT Madras</span>
                            <span class="year_tag">2017</span>
                        </div>
                    </h2>
                    <p>As part of a team of five students at IIT Madras, we developed the institute's first solar-powered airplane that successfully taxied under its own power. I designed and fabricated a solar cell array and battery pack, managed the electrical subsystem, and contributed to the aerodynamic design, ensuring the aircraft's operational efficiency. The airplane, with a 3-meter wingspan and equipped with 52 SunPower C60 cells, demonstrated the effectiveness of our solar power design.</p>


                    <div class="video_placeholder">
                        <img width="900px" height="auto" src="https://dl.dropbox.com/scl/fi/hidwy1kckhfbw8f90he2w/solar_airplane.jpg?rlkey=qgevz0y8z1fve0u49gp00wbrq&st=zgm2j813&dl=0" alt="Solar-Powered Airplane" class="dynamic-image">
                    </div>
                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://raftlab.iitm.ac.in/" target="_blank">Visit the project page</a>
                    </div>
                </div>
                
            
            </div>

            <!-- CLASS PHYSICS ENGINES -->

            <div class="project_class toggle" data-target="physics" onclick="toggleContent()">
                <h1 class="class_title">
                    Physics Engines
                </h1>
                <!-- content 1 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        MuJoCo Simulink Blockset
                        <div class="org_year">
                            <span class="org_name">MathWorks</span>
                            <span class="year_tag">2022-2023</span>
                        </div>
                    </h2>
                    <p>Developed a Simulink Blockset for the MuJoCo simulator, enabling high-performance robot simulation and autonomous algorithm development within Simulink. The blockset uses C++ MEX S-Functions to interface directly with the MuJoCo API, providing real-time access to actuators and sensors, along with camera rendering within Simulink.</p>
                    <div class="video_placeholder">
                        <iframe width="900" height="506" src="https://www.youtube.com/embed/wVSQ-lmArJY?rel=0&vq=hd1080" 
                        title="YouTube video player" frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
                        allowfullscreen></iframe>
                    </div>

                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://github.com/mathworks-robotics/mujoco-simulink-blockset" target="_blank">Visit the project page</a>
                    </div>
                </div>
                <!-- content 2 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        VEX Mobile Robot Simulation in Gazebo
                        <div class="org_year">
                            <span class="org_name">MathWorks</span>
                            <span class="year_tag">2020-2021</span>
                        </div>
                    </h2>
                    <p>Developed realistic models of VEX Mobile Robot in Gazebo, including mechanisms like skid steer drive, grippers, four-bar linkages, and gears. The work involved exact CAD modeling and setting up critical parameters such as inertia, friction, and stiffness coefficients. The Gazebo model was then interfaced with Simulink using the Robotics System Toolbox for seamless integration.</p>
                    <div class="video_placeholder">
                        <img src="https://www.mathworks.com/help/rtw/vexv5/ug/vexv5_pick_place.gif" alt="VEX Robot Pick and Place Animation" width="900" height="auto" class="dynamic-image"/>
                    </div>
                
                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://www.mathworks.com/help/rtw/vexv5/ug/simulate-vex-simulink-gazebo.html" target="_blank">Visit the project page</a>
                    </div>
                </div>

                <!-- content 3 -->
                <div id="class_section" class="content">
                    <h2 class="project_title">
                        Vision-Centric Quadrotor Simulator in Blender
                        <div class="org_year">
                            <span class="org_name">Worcester Polytechnic Institute</span>
                            <span class="year_tag">2023</span>
                        </div>
                    </h2>
                    <p>Blender is excellent for simulating vision systems like cameras and depth sensors, but lacks built-in dynamics for accurate UAV simulation. To overcome this, I rewrote the quadrotor physics and controllers from scratch in Python and integrated them with Blender using its Python scripting APIs. The simulator was used in motion planning assignments for the Aerial Robotics course at WPI. I was responsible for implementing the dynamics, control systems, state machines, and API integration. Camera rendering was done in collaboration with Siyuan Huang (MS WPI).</p>
                    <div class="video_placeholder">
                        <img src="https://dl.dropbox.com/scl/fi/zvynn0qfaxhd269vusypu/BlenderQuadrotor.jpg?rlkey=pvjbpk4jjmk9xinxzh1efo7vf&st=f8o8391l&dl=0" alt="Blender Quadrotor Simulation" max-width="900" height="auto" class="dynamic-image"/>
                    </div>
                
                    <div style="text-align: center; margin-top: 10px;">
                        <a href="https://rbe549.github.io/rbe595/fall2023/proj/p0/" target="_blank">Visit the course page</a>
                    </div>
                </div>
            
            </div>

        </div>
    </section>

    <script>
        videojs(document.querySelector('#my-video'));
      </script>
</body>
</html>
